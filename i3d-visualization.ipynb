{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import i3d\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build Joint Stream Graph (from i3d.py)\n",
    "\"\"\"\n",
    "_IMAGE_SIZE = 224\n",
    "_NUM_CLASSES = 400\n",
    "\n",
    "_SAMPLE_VIDEO_FRAMES = 25\n",
    "_SAMPLE_PATHS = {\n",
    "    'rgb': 'data/v_CricketShot_g04_c01_rgb.npy',\n",
    "    'flow': 'data/v_CricketShot_g04_c01_flow.npy',\n",
    "}\n",
    "\n",
    "_CHECKPOINT_PATHS = {\n",
    "    'rgb': 'data/checkpoints/rgb_scratch/model.ckpt',\n",
    "    'flow': 'data/checkpoints/flow_scratch/model.ckpt',\n",
    "    'rgb_imagenet': 'data/checkpoints/rgb_imagenet/model.ckpt',\n",
    "    'flow_imagenet': 'data/checkpoints/flow_imagenet/model.ckpt',\n",
    "}\n",
    "\n",
    "_LABEL_MAP_PATH = 'data/label_map.txt'\n",
    "\n",
    "\n",
    "\n",
    "imagenet_pretrained = True # use pretrained model as it had better performance\n",
    "eval_type = \"joint\" # build the graph for both streams \n",
    "tf.reset_default_graph() # reset graph each time cell is run, prevents duplicate variables\n",
    "\n",
    "if eval_type not in ['rgb', 'flow', 'joint']:\n",
    "    raise ValueError('Bad `eval_type`, must be one of rgb, flow, joint')\n",
    "\n",
    "kinetics_classes = [x.strip() for x in open(_LABEL_MAP_PATH)]\n",
    "\n",
    "if eval_type in ['rgb', 'joint']:\n",
    "    # RGB input has 3 channels.\n",
    "    rgb_input = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(1, None, _IMAGE_SIZE, _IMAGE_SIZE, 3))\n",
    "    with tf.variable_scope('RGB'):\n",
    "        rgb_model = i3d.InceptionI3d(\n",
    "            _NUM_CLASSES, spatial_squeeze=True, final_endpoint='Logits')\n",
    "        rgb_logits, _ = rgb_model(\n",
    "            rgb_input, is_training=False, dropout_keep_prob=1.0)\n",
    "    rgb_variable_map = {}\n",
    "    for variable in tf.global_variables():\n",
    "        if variable.name.split('/')[0] == 'RGB':\n",
    "            rgb_variable_map[variable.name.replace(':0', '')] = variable\n",
    "    rgb_saver = tf.train.Saver(var_list=rgb_variable_map, reshape=True)\n",
    "\n",
    "if eval_type in ['flow', 'joint']:\n",
    "    # Flow input has only 2 channels.\n",
    "    flow_input = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape=(1, None, _IMAGE_SIZE, _IMAGE_SIZE, 2))\n",
    "    with tf.variable_scope('Flow'):\n",
    "        flow_model = i3d.InceptionI3d(\n",
    "            _NUM_CLASSES, spatial_squeeze=True, final_endpoint='Logits')\n",
    "        flow_logits, _ = flow_model(\n",
    "            flow_input, is_training=False, dropout_keep_prob=1.0)\n",
    "    flow_variable_map = {}\n",
    "    for variable in tf.global_variables():\n",
    "        if variable.name.split('/')[0] == 'Flow':\n",
    "            flow_variable_map[variable.name.replace(':0', '')] = variable\n",
    "    flow_saver = tf.train.Saver(var_list=flow_variable_map, reshape=True)\n",
    "\n",
    "if eval_type == 'rgb':\n",
    "    model_logits = rgb_logits\n",
    "elif eval_type == 'flow':\n",
    "    model_logits = flow_logits\n",
    "else:\n",
    "    model_logits = rgb_logits + flow_logits\n",
    "model_predictions = tf.nn.softmax(model_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run sample (playing cricket) prediction with joint\n",
    "\"\"\"\n",
    "eval_type = \"joint\"\n",
    "with tf.Session() as sess:\n",
    "        feed_dict = {}\n",
    "        if eval_type in ['rgb', 'joint']:\n",
    "            if imagenet_pretrained:\n",
    "                rgb_saver.restore(sess, _CHECKPOINT_PATHS['rgb_imagenet'])\n",
    "            else:\n",
    "                rgb_saver.restore(sess, _CHECKPOINT_PATHS['rgb'])\n",
    "            tf.logging.info('RGB checkpoint restored')\n",
    "            rgb_sample = np.load(_SAMPLE_PATHS['rgb'])\n",
    "            print(\"RGB size:\", rgb_sample.shape)\n",
    "            tf.logging.info('RGB data loaded, shape=%s', str(rgb_sample.shape))\n",
    "            feed_dict[rgb_input] = rgb_sample\n",
    "\n",
    "        if eval_type in ['flow', 'joint']:\n",
    "            if imagenet_pretrained:\n",
    "                flow_saver.restore(sess, _CHECKPOINT_PATHS['flow_imagenet'])\n",
    "            else:\n",
    "                flow_saver.restore(sess, _CHECKPOINT_PATHS['flow'])\n",
    "            tf.logging.info('Flow checkpoint restored')\n",
    "            flow_sample = np.load(_SAMPLE_PATHS['flow'])\n",
    "            print(\"flow size:\", flow_sample.shape)\n",
    "            tf.logging.info('Flow data loaded, shape=%s',\n",
    "                            str(flow_sample.shape))\n",
    "            feed_dict[flow_input] = flow_sample\n",
    "        # print(\"feed_dict\", feed_dict)\n",
    "        out_logits, out_predictions = sess.run(\n",
    "            [model_logits, model_predictions],\n",
    "            feed_dict=feed_dict)\n",
    "\n",
    "        out_logits = out_logits[0]\n",
    "        out_predictions = out_predictions[0]\n",
    "        sorted_indices = np.argsort(out_predictions)[::-1]\n",
    "\n",
    "        print('Norm of logits: %f' % np.linalg.norm(out_logits))\n",
    "        print('\\nTop classes and probabilities')\n",
    "        for index in sorted_indices[:20]:\n",
    "            print(out_predictions[index], out_logits[\n",
    "                  index], kinetics_classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "def blur_image(X, sigma=1):\n",
    "    # start = time.time()\n",
    "    X = gaussian_filter1d(X, sigma, axis=1)\n",
    "    X = gaussian_filter1d(X, sigma, axis=2)\n",
    "    X = gaussian_filter1d(X, sigma, axis=3)\n",
    "    # print(\"Blur time\", time.time()-start)\n",
    "    return X\n",
    "\n",
    "\n",
    "def create_flow_image(X):\n",
    "        return np.append(X + 0.5, 0.5 * np.ones((224, 224, 1)), axis=2)\n",
    "\n",
    "\n",
    "def save_gif(X, class_name, stream_type):\n",
    "    # save all frames\n",
    "    num_frames = X.shape[1]\n",
    "    directory = \"experiments_{}/{}/\".format(stream_type, class_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    image_name = \"{}_{}\".format(class_name, stream_type)\n",
    "    file_name = directory + image_name + \"{}.png\"\n",
    "    print(\"file_name\", file_name)\n",
    "    filenames = []\n",
    "    for i in range(0, num_frames):\n",
    "        if stream_type == \"rgb\":\n",
    "            plt.imshow(X[0][i])\n",
    "        elif stream_type == \"flow\":\n",
    "            plt.imshow(create_flow_image(X[0][i]))\n",
    "        \n",
    "        filename = file_name.format(i)\n",
    "        filenames.append(filename)\n",
    "        plt.savefig(filename.format(i))\n",
    "        # plt.show()\n",
    "    \n",
    "    #create gif\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(filename))\n",
    "        imageio.mimsave(directory + \"/{}\".format(image_name) + \".gif\", images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_visualization(sess, rgb_input, flow_input, target_y, logits, class_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate an image to maximize the score of target_y under a pretrained model.\n",
    "    \n",
    "    Inputs:\n",
    "    - target_y: Integer in the range [0, 1000) giving the index of the class\n",
    "    - model: A pretrained CNN that will be used to generate the image\n",
    "    \n",
    "    Keyword arguments:\n",
    "    - l2_reg: Strength of L2 regularization on the image\n",
    "    - learning_rate: How big of a step to take\n",
    "    - num_iterations: How many iterations to use\n",
    "    - blur_every: How often to blur the image as an implicit regularizer\n",
    "    - max_jitter: How much to gjitter the image as an implicit regularizer\n",
    "    - show_every: How often to show the intermediate result\n",
    "    \"\"\"\n",
    "    print(\"params\", kwargs)\n",
    "    l2_reg = kwargs.pop('l2_reg', 1e-3)\n",
    "    learning_rate = kwargs.pop('learning_rate', 25)\n",
    "    num_iterations = kwargs.pop('num_iterations', 100)\n",
    "    blur_every = kwargs.pop('blur_every', 4)\n",
    "    max_jitter = kwargs.pop('max_jitter', 16)\n",
    "    show_every = kwargs.pop('show_every', 25)\n",
    "    num_frames = kwargs.pop('num_frames', 25)\n",
    "    stream_type = kwargs.pop('stream_type', 'rgb')\n",
    "    sigma = kwargs.pop('sigma', 1)\n",
    "    \n",
    "    # X = np.random.rand(num_frames, 224, 224, 3)\n",
    "    if stream_type == 'rgb':\n",
    "        stream_input = rgb_input\n",
    "        X = np.random.rand(1, 224, 224, 3) * np.ones((num_frames, 224, 224, 3))\n",
    "        X = X[None]\n",
    "    elif stream_type == 'flow':\n",
    "        stream_input = flow_input\n",
    "        # may need to change noise instiantiation\n",
    "        X = np.random.rand(1, 224, 224, 2) * np.ones((num_frames, 224, 224, 2))\n",
    "        # preprocess as described in paper\n",
    "        X = X - .5\n",
    "        X = X[None]\n",
    "        X = flow_sample\n",
    "    \n",
    "    loss = logits[0, target_y] # scalar loss\n",
    "\n",
    "    grad = tf.gradients(loss, stream_input) # compute gradient\n",
    "    grad = tf.squeeze(grad) - l2_reg*2*stream_input # regualarlize gradient\n",
    "\n",
    "    start_time = time.time()\n",
    "    for t in range(num_iterations):\n",
    "        \n",
    "        # Randomly jitter the image a bit; this gives slightly nicer results\n",
    "        ox, oy = np.random.randint(-max_jitter, max_jitter+1, 2)\n",
    "        Xi = X.copy()\n",
    "        X = np.roll(np.roll(X, ox, 1), oy, 2)\n",
    "\n",
    "        # we want logits for loss, model.classifier are just logits\n",
    "        loss = logits[0, target_y] # scalar loss\n",
    "\n",
    "        # model.image is just the data matrix input (a gif in our case)\n",
    "        gradient_step = sess.run(grad, feed_dict={stream_input:X})\n",
    "        X += learning_rate * gradient_step\n",
    "\n",
    "        # Undo the jitter\n",
    "        X = np.roll(np.roll(X, -ox, 1), -oy, 2)\n",
    "\n",
    "        # As a regularizer, clip and periodically blur\n",
    "        if stream_type == 'flow':\n",
    "            X = np.clip(X, -0.5, 0.5)\n",
    "        if t % blur_every == 0:\n",
    "            X = blur_image(X, sigma=sigma)\n",
    "        \n",
    "        print(\"iteration:\", t, time.time()-start_time)\n",
    "        \n",
    "        # Periodically show the image\n",
    "        if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:\n",
    "            \n",
    "            if stream_type == \"rgb\":\n",
    "                plt.imshow(X[0][0])\n",
    "            elif stream_type == \"flow\":\n",
    "                plt.imshow(create_flow_image(X[0][0]))\n",
    "          \n",
    "            if t == num_iterations-1:\n",
    "                save_gif(X, class_name, stream_type)\n",
    "                    \n",
    "            plt.title('{}_{}\\nIteration {} / {}'.format(class_name, stream_type, t + 1, num_iterations))\n",
    "            plt.gcf().set_size_inches(4, 4)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run RGB visualization only\n",
    "\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(model_logits)\n",
    "print(rgb_input)\n",
    "target = 6\n",
    "print(kinetics_classes[target])\n",
    "action_name = kinetics_classes[target].replace(\" \", \"_\")\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    with tf.Session() as sess:\n",
    "        # THIS LINE NEEDS TO BE MOVED\n",
    "        rgb_saver.restore(sess, _CHECKPOINT_PATHS['rgb_imagenet'])\n",
    "        # number of frames must be >= 9 or else kernel crashes\n",
    "        rgb_visual_gif = create_class_visualization(sess, rgb_input, flow_input, target, rgb_logits, action_name + \"test\", \n",
    "                                   stream_type='rgb', num_frames=25, num_iterations=250, learning_rate=1.5, \n",
    "                                   blur_every=3, max_jitter=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run FLOW visualization only\n",
    "\"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(model_logits)\n",
    "print(flow_input)\n",
    "target = 171\n",
    "print(kinetics_classes[target])\n",
    "action_name = kinetics_classes[target].replace(\" \", \"_\")\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    with tf.Session() as sess:\n",
    "        # THIS LINE NEEDS TO BE MOVED\n",
    "        flow_saver.restore(sess, _CHECKPOINT_PATHS['flow_imagenet'])\n",
    "        flow_visual_gif = create_class_visualization(sess, rgb_input, flow_input, target, flow_logits, action_name + \"test\", stream_type='flow', num_frames=25, num_iterations=1000, l2_reg=1e-2, learning_rate=1.5, blur_every=10, max_jitter=32, sigma=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Print all classes\n",
    "\"\"\"\n",
    "indexes = range(len(kinetics_classes))\n",
    "class_to_index = dict(zip(kinetics_classes, indexes))\n",
    "index_to_class = dict(zip(indexes, kinetics_classes))\n",
    "#print(index_to_class)\n",
    "\n",
    "temp = np.append(0*np.ones((224, 224, 1)), -.205*np.ones((224, 224, 1)), axis=2)\n",
    "plt.imshow(create_flow_image(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
