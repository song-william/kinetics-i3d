{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import i3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_class_visualization(target_y, logits, rgb_input, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate an image to maximize the score of target_y under a pretrained model.\n",
    "    \n",
    "    Inputs:\n",
    "    - target_y: Integer in the range [0, 1000) giving the index of the class\n",
    "    - model: A pretrained CNN that will be used to generate the image\n",
    "    \n",
    "    Keyword arguments:\n",
    "    - l2_reg: Strength of L2 regularization on the image\n",
    "    - learning_rate: How big of a step to take\n",
    "    - num_iterations: How many iterations to use\n",
    "    - blur_every: How often to blur the image as an implicit regularizer\n",
    "    - max_jitter: How much to gjitter the image as an implicit regularizer\n",
    "    - show_every: How often to show the intermediate result\n",
    "    \"\"\"\n",
    "    l2_reg = kwargs.pop('l2_reg', 1e-3)\n",
    "    learning_rate = kwargs.pop('learning_rate', 25)\n",
    "    num_iterations = kwargs.pop('num_iterations', 100)\n",
    "    blur_every = kwargs.pop('blur_every', 10)\n",
    "    max_jitter = kwargs.pop('max_jitter', 16)\n",
    "    show_every = kwargs.pop('show_every', 25)\n",
    "\n",
    "    X = 255 * np.random.rand(79, 224, 224, 3)\n",
    "    #X = preprocess_image(X)[None]\n",
    "    \n",
    "    ########################################################################\n",
    "    # TODO: Compute the loss and the gradient of the loss with respect to  #\n",
    "    # the input image, model.image. We compute these outside the loop so   #\n",
    "    # that we don't have to recompute the gradient graph at each iteration #\n",
    "    #                                                                      #\n",
    "    # Note: loss and grad should be TensorFlow Tensors, not numpy arrays!  #\n",
    "    #                                                                      #\n",
    "    # The loss is the score for the target label, target_y. You should     #\n",
    "    # use model.classifier to get the scores, and tf.gradients to compute  #\n",
    "    # gradients. Don't forget the (subtracted) L2 regularization term!     #\n",
    "    ########################################################################\n",
    "    # logits command\n",
    "    # loss = model.classifier[0, target_y] # scalar loss\n",
    "    loss = logits[0, target_y] # scalar loss\n",
    "    \n",
    "    # model.image is just input data \n",
    "    # self.image = tf.placeholder('float',shape=[None,None,None,3],name='input_image')\n",
    "    # grad = tf.gradients(loss, model.image) # gradient of loss with respect to model.image, same size as model.image\n",
    "    # grad = tf.squeeze(grad) - l2_reg*2*model.image\n",
    "    \n",
    "    grad = tf.gradients(loss, rgb_input)\n",
    "    grad = tf.squeeze(grad) - l2_reg*2*rgb_input\n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "\n",
    "    \n",
    "    for t in range(num_iterations):\n",
    "        # Randomly jitter the image a bit; this gives slightly nicer results\n",
    "        ox, oy = np.random.randint(-max_jitter, max_jitter+1, 2)\n",
    "        Xi = X.copy()\n",
    "        X = np.roll(np.roll(X, ox, 1), oy, 2)\n",
    "        \n",
    "        ########################################################################\n",
    "        # TODO: Use sess to compute the value of the gradient of the score for #\n",
    "        # class target_y with respect to the pixels of the image, and make a   #\n",
    "        # gradient step on the image using the learning rate. You should use   #\n",
    "        # the grad variable you defined above.                                 #\n",
    "        #                                                                      #\n",
    "        # Be very careful about the signs of elements in your code.            #\n",
    "        ########################################################################\n",
    "        # we want logits for loss, model.classifier are just logits\n",
    "        # loss = model.classifier[0, target_y] # scalar loss\n",
    "        loss = logits[0, target_y] # scalar loss\n",
    "        \n",
    "        # model.image is just the data matrix input (a gif in our case)\n",
    "        # gradient_step = sess.run(grad, feed_dict={model.image:X})\n",
    "        gradient_step = sess.run(grad, feed_dict={rgb_input:X})\n",
    "        X += learning_rate * gradient_step\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "\n",
    "        # Undo the jitter\n",
    "        X = np.roll(np.roll(X, -ox, 1), -oy, 2)\n",
    "\n",
    "        # As a regularizer, clip and periodically blur\n",
    "        X = np.clip(X, -SQUEEZENET_MEAN/SQUEEZENET_STD, (1.0 - SQUEEZENET_MEAN)/SQUEEZENET_STD)\n",
    "        if t % blur_every == 0:\n",
    "            X = blur_image(X, sigma=0.5)\n",
    "\n",
    "        # Periodically show the image\n",
    "        if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:\n",
    "            #plt.imshow(deprocess_image(X[0]))\n",
    "            plt.imshow(X[0][0])\n",
    "            class_name = class_names[target_y]\n",
    "            plt.title('%s\\nIteration %d / %d' % (class_name, t + 1, num_iterations))\n",
    "            plt.gcf().set_size_inches(4, 4)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build RBG Graph\n",
    "\"\"\"\n",
    "_IMAGE_SIZE = 224\n",
    "_NUM_CLASSES = 400\n",
    "\n",
    "_SAMPLE_VIDEO_FRAMES = 79\n",
    "_SAMPLE_PATHS = {\n",
    "    'rgb': 'data/v_CricketShot_g04_c01_rgb.npy',\n",
    "    'flow': 'data/v_CricketShot_g04_c01_flow.npy',\n",
    "}\n",
    "\n",
    "_CHECKPOINT_PATHS = {\n",
    "    'rgb': 'data/checkpoints/rgb_scratch/model.ckpt',\n",
    "    'flow': 'data/checkpoints/flow_scratch/model.ckpt',\n",
    "    'rgb_imagenet': 'data/checkpoints/rgb_imagenet/model.ckpt',\n",
    "    'flow_imagenet': 'data/checkpoints/flow_imagenet/model.ckpt',\n",
    "}\n",
    "\n",
    "_LABEL_MAP_PATH = 'data/label_map.txt'\n",
    "\n",
    "#FLAGS = tf.flags.FLAGS\n",
    "\n",
    "#tf.flags.DEFINE_string('eval_type', 'joint', 'rgb, flow, or joint')\n",
    "#tf.flags.DEFINE_boolean('imagenet_pretrained', True, '')\n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#eval_type = FLAGS.eval_type\n",
    "#imagenet_pretrained = FLAGS.imagenet_pretrained\n",
    "kinetics_classes = [x.strip() for x in open(_LABEL_MAP_PATH)]\n",
    "rgb_input = tf.placeholder(tf.float32, shape=(1, _SAMPLE_VIDEO_FRAMES, _IMAGE_SIZE, _IMAGE_SIZE, 3))\n",
    "with tf.variable_scope('RGB'):\n",
    "        rgb_model = i3d.InceptionI3d(_NUM_CLASSES, spatial_squeeze=True, final_endpoint='Logits')\n",
    "        rgb_logits, _ = rgb_model(rgb_input, is_training=False, dropout_keep_prob=1.0)\n",
    "rgb_variable_map = {}\n",
    "for variable in tf.global_variables():\n",
    "    if variable.name.split('/')[0] == 'RGB':\n",
    "        rgb_variable_map[variable.name.replace(':0', '')] = variable\n",
    "rgb_saver = tf.train.Saver(var_list=rgb_variable_map, reshape=True)\n",
    "model_logits = rgb_logits\n",
    "model_predictions = tf.nn.softmax(model_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiener\n",
      "pretrained\n",
      "INFO:tensorflow:Restoring parameters from data/checkpoints/rgb_imagenet/model.ckpt\n",
      "INFO:tensorflow:RGB checkpoint restored\n",
      "RGB size: (1, 79, 224, 224, 3)\n",
      "INFO:tensorflow:RGB data loaded, shape=(1, 79, 224, 224, 3)\n",
      "wiener1\n",
      "wiener2\n",
      "Norm of logits: 87.108871\n",
      "\n",
      "Top classes and probabilities\n",
      "0.9999968 25.856646 playing cricket\n",
      "1.335354e-06 12.330335 playing kickball\n",
      "4.553142e-07 11.254371 catching or throwing baseball\n",
      "3.1434254e-07 10.883866 shooting goal (soccer)\n",
      "1.9243305e-07 10.393131 catching or throwing softball\n",
      "1.309655e-07 10.008317 throwing discus\n",
      "1.0681848e-07 9.804514 javelin throw\n",
      "9.446425e-08 9.681604 golf putting\n",
      "7.842931e-08 9.49558 jogging\n",
      "7.801767e-08 9.490318 hitting baseball\n",
      "6.608518e-08 9.3243265 triple jump\n",
      "3.4878482e-08 8.685253 hurling (sport)\n",
      "2.996574e-08 8.533437 skateboarding\n",
      "2.1083935e-08 8.181894 hurdling\n",
      "2.0079328e-08 8.133075 playing tennis\n",
      "1.8454037e-08 8.048665 breakdancing\n",
      "1.7050859e-08 7.969584 hammer throw\n",
      "1.7004545e-08 7.9668636 shot put\n",
      "1.4611408e-08 7.8151855 long jump\n",
      "1.4274541e-08 7.7918606 headbutting\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run sample prediction with RBG only\n",
    "\"\"\"\n",
    "eval_type = 'rgb'\n",
    "imagenet_pretrained = True\n",
    "print(\"wiener\")\n",
    "with tf.Session() as sess:\n",
    "        feed_dict = {}\n",
    "        if eval_type in ['rgb', 'joint']:\n",
    "            if imagenet_pretrained:\n",
    "                print(\"pretrained\")\n",
    "                rgb_saver.restore(sess, _CHECKPOINT_PATHS['rgb_imagenet'])\n",
    "            else:\n",
    "                rgb_saver.restore(sess, _CHECKPOINT_PATHS['rgb'])\n",
    "            tf.logging.info('RGB checkpoint restored')\n",
    "            rgb_sample = np.load(_SAMPLE_PATHS['rgb'])\n",
    "            print(\"RGB size:\", rgb_sample.shape)\n",
    "            tf.logging.info('RGB data loaded, shape=%s', str(rgb_sample.shape))\n",
    "            feed_dict[rgb_input] = rgb_sample\n",
    "\n",
    "        if eval_type in ['flow', 'joint']:\n",
    "            if imagenet_pretrained:\n",
    "                flow_saver.restore(sess, _CHECKPOINT_PATHS['flow_imagenet'])\n",
    "            else:\n",
    "                flow_saver.restore(sess, _CHECKPOINT_PATHS['flow'])\n",
    "            tf.logging.info('Flow checkpoint restored')\n",
    "            flow_sample = np.load(_SAMPLE_PATHS['flow'])\n",
    "            print(\"flow size:\", flow_sample.shape)\n",
    "            tf.logging.info('Flow data loaded, shape=%s',\n",
    "                            str(flow_sample.shape))\n",
    "            feed_dict[flow_input] = flow_sample\n",
    "        print(\"wiener1\")\n",
    "        out_logits, out_predictions = sess.run(\n",
    "            [model_logits, model_predictions],\n",
    "            feed_dict=feed_dict)\n",
    "        print(\"wiener2\")\n",
    "        out_logits = out_logits[0]\n",
    "        out_predictions = out_predictions[0]\n",
    "        sorted_indices = np.argsort(out_predictions)[::-1]\n",
    "\n",
    "        print('Norm of logits: %f' % np.linalg.norm(out_logits))\n",
    "        print('\\nTop classes and probabilities')\n",
    "        for index in sorted_indices[:20]:\n",
    "            print(out_predictions[index], out_logits[\n",
    "                  index], kinetics_classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
